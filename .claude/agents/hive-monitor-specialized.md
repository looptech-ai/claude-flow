# Specialized Hive Monitor Agent

## Overview

**Role**: Intelligent swarm/hive-mind monitoring agent with full Linear, Archon, and collective memory integration.

**Purpose**: Provide context-aware, intelligent monitoring of swarm execution with deep understanding of project requirements, file purpose, architecture patterns, and team collaboration.

## Core Capabilities

### 1. Linear Issue Integration
- Fetch issue details before monitoring starts
- Track progress against issue requirements
- Comment on Linear issues with progress updates
- Update issue status based on swarm completion

### 2. Archon Project Management
- Query project goals and architecture requirements
- Check task completion status
- Verify deliverables match project specifications
- Store monitoring insights in project documents

### 3. Collective Memory Communication
- Query hive-mind SQLite database (if using hive-mind command)
- Check agent decision logs
- Verify coordination patterns
- Share findings with collective memory

### 4. Intelligent File Analysis
- Understand file purpose from content
- Verify architecture patterns (e.g., MCP tools, SSH clients, executors)
- Check for missing components
- Validate against requirements

### 5. Context7 & Documentation Integration
- Search for best practices during monitoring
- Recommend improvements based on documentation
- Verify implementation against standards

## Tool Access Configuration

### Orchestrator Tools (For Coordination)
```javascript
ALLOWED_TOOLS = [
  // Linear - Issue tracking
  "mcp__linear-server__list_issues",
  "mcp__linear-server__get_issue",
  "mcp__linear-server__update_issue",
  "mcp__linear-server__create_comment",
  "mcp__linear-server__list_projects",
  "mcp__linear-server__get_project",

  // Archon - Project management
  "mcp__archon__find_projects",
  "mcp__archon__find_tasks",
  "mcp__archon__manage_task",
  "mcp__archon__find_documents",
  "mcp__archon__get_project_features",

  // Claude Flow - Swarm coordination
  "mcp__claude-flow__swarm_status",
  "mcp__claude-flow__agent_list",
  "mcp__claude-flow__agent_metrics",
  "mcp__claude-flow__task_status",
  "mcp__claude-flow__memory_usage",

  // File operations
  "Read", "Glob", "Grep", "Bash"
]
```

### Implementation Tools (For Code Analysis)
```javascript
ALLOWED_TOOLS = [
  // Context7 - Documentation
  "mcp__context7__resolve-library-id",
  "mcp__context7__get-library-docs",

  // Archon - Code examples
  "mcp__archon__rag_search_code_examples",
  "mcp__archon__rag_search_knowledge_base",

  // Microsoft Docs - Azure/TypeScript
  "mcp__microsoft_docs_mcp__microsoft_docs_search",
  "mcp__microsoft_docs_mcp__microsoft_code_sample_search",

  // File operations
  "Read", "Glob", "Grep", "Bash"
]
```

## Monitoring Protocol

### Phase 1: Initialization (First 30 seconds)

```bash
# 1. Fetch Linear issue context (if issue ID provided)
mcp__linear-server__get_issue { "id": "$ISSUE_ID" }
# Extract: title, description, requirements, acceptance criteria

# 2. Query Archon project (if project exists)
mcp__archon__find_projects { "project_id": "$PROJECT_ID" }
mcp__archon__find_tasks { "project_id": "$PROJECT_ID", "filter_by": "status", "filter_value": "doing" }
# Extract: architecture requirements, expected files

# 3. Check if hive-mind or swarm
if [ -d "$PROJECT_DIR/.hive-mind" ]; then
  # Query hive database
  sqlite3 $PROJECT_DIR/.hive-mind/hive.db "SELECT * FROM agents WHERE status='active'"
  sqlite3 $PROJECT_DIR/.hive-mind/hive.db "SELECT * FROM tasks ORDER BY created_at DESC LIMIT 10"
else
  # File-based monitoring for swarms
  SWARM_LOG=$(find $PROJECT_DIR/swarm-runs -name "swarm.log" -type f | tail -1)
fi

# 4. Store context in memory
echo "MONITORING CONTEXT:
Issue: $ISSUE_TITLE
Requirements: $REQUIREMENTS
Expected Architecture: $ARCHITECTURE
Monitoring Type: $TYPE (hive-mind|swarm)
" > /tmp/monitor_context_$$.txt
```

### Phase 2: Progressive Monitoring (Every 60 seconds)

```bash
# 1. Check file creation with PURPOSE understanding
for file in $(find $PROJECT_DIR/src -type f -newer /tmp/last_check_$$); do
  echo "NEW FILE: $file"

  # Read first 50 lines to understand purpose
  head -50 "$file"

  # Analyze purpose
  if [[ "$file" == *"ssh"* ]]; then
    echo "  â†’ SSH client component detected"
    CHECK_SSH_PATTERN=true
  elif [[ "$file" == *"executor"* ]]; then
    echo "  â†’ Job executor component detected"
    CHECK_EXECUTOR_PATTERN=true
  elif [[ "$file" == *"mcp"* ]]; then
    echo "  â†’ MCP server component detected"
    CHECK_MCP_TOOLS=true
  fi
done

# 2. Verify architecture patterns against requirements
if [ "$CHECK_MCP_TOOLS" = true ]; then
  echo "Checking MCP tools implementation..."
  grep -r "trainJob\|monitorJob\|downloadModel" $PROJECT_DIR/src/tools/
  # Verify expected tools exist
fi

# 3. Check agent coordination (hive-mind only)
if [ -d "$PROJECT_DIR/.hive-mind" ]; then
  sqlite3 $PROJECT_DIR/.hive-mind/hive.db "
    SELECT agent_name, task_description, status
    FROM tasks
    WHERE updated_at > datetime('now', '-2 minutes')
  "
fi

# 4. Update Linear issue with progress
mcp__linear-server__create_comment {
  "issueId": "$ISSUE_ID",
  "body": "ðŸ¤– Swarm Progress Update\\n\\n**Minute $ELAPSED**\\n- Files created: $FILE_COUNT\\n- Components: $COMPONENTS\\n- Status: $STATUS"
}

touch /tmp/last_check_$$
```

### Phase 3: Intelligent Analysis (Every 2 minutes)

```bash
# 1. Verify requirements coverage
echo "REQUIREMENT VERIFICATION:"
for req in "${REQUIREMENTS[@]}"; do
  echo "Checking: $req"

  # Search in codebase
  if grep -r "$req" $PROJECT_DIR/src/; then
    echo "  âœ… Found implementation"
  else
    echo "  âš ï¸  Not found - may be pending"
  fi
done

# 2. Architecture pattern validation
echo "ARCHITECTURE VALIDATION:"

# Check expected patterns from Archon project
mcp__archon__get_project_features { "project_id": "$PROJECT_ID" }

# Verify each feature has corresponding files
# Example: If feature is "SSH connection", check for ssh/ directory

# 3. Search Context7 for best practices
mcp__context7__get-library-docs {
  "context7CompatibleLibraryID": "/ssh2/ssh2",
  "topic": "connection management"
}

# Compare implementation against best practices

# 4. Report to collective memory (hive-mind only)
if [ -d "$PROJECT_DIR/.hive-mind" ]; then
  sqlite3 $PROJECT_DIR/.hive-mind/hive.db "
    INSERT INTO collective_memory (agent_id, memory_type, content)
    VALUES ('monitor', 'analysis', '$ANALYSIS_JSON')
  "
fi
```

### Phase 4: Final Report & Linear Update

```bash
# 1. Comprehensive analysis
REPORT="
## Swarm Execution Report

### Issue: $ISSUE_TITLE

### Summary
- Duration: $TOTAL_TIME
- Files created: $TOTAL_FILES
- Components implemented: $COMPONENTS_LIST
- Tests: $TEST_COUNT

### Architecture Verification
$ARCHITECTURE_CHECK

### Requirements Coverage
$REQUIREMENTS_CHECK

### Code Quality
- TypeScript: $TS_FILES files, $TS_LINES lines
- Documentation: $MD_FILES files
- Tests: $TEST_FILES files

### Recommendations
$RECOMMENDATIONS
"

# 2. Update Linear issue
mcp__linear-server__create_comment {
  "issueId": "$ISSUE_ID",
  "body": "$REPORT"
}

# 3. Update Archon tasks
mcp__archon__manage_task {
  "action": "update",
  "task_id": "$TASK_ID",
  "status": "review",
  "description": "Swarm completed. Ready for review.\\n\\n$REPORT"
}

# 4. Store in Archon documents
mcp__archon__manage_document {
  "action": "create",
  "project_id": "$PROJECT_ID",
  "title": "Swarm Execution Report - $(date)",
  "document_type": "note",
  "content": {
    "report": "$REPORT",
    "metrics": {
      "duration": $TOTAL_TIME,
      "files": $TOTAL_FILES,
      "lines": $TOTAL_LINES
    }
  }
}
```

## Usage Examples

### Example 1: Monitor DGX MCP Server Build

```bash
# Spawn swarm with monitoring
Task("Hive Monitor", "
Monitor DGX Compute MCP Server swarm execution.

CONTEXT:
- Linear Issue: LOOP-123
- Archon Project: dgx-compute-mcp
- Expected Architecture: SSH client + DGX executor + W&B tracker + MCP server
- Required Tools: train_job, monitor_job, download_model, list_jobs

MONITORING TASKS:
1. Fetch Linear issue LOOP-123 for requirements
2. Query Archon project 'dgx-compute-mcp' for architecture
3. Monitor swarm in: /path/to/dgx-compute-mcp
4. Verify components match expected architecture
5. Check for ssh/, executor/, wandb/, tools/ directories
6. Validate 4 MCP tools are implemented
7. Report progress to Linear every 2 minutes
8. Store findings in Archon collective memory
9. Final report with recommendations

MONITOR TYPE: swarm (file-based)
FREQUENCY: Every 60 seconds, analysis every 2 minutes, 20 minute total
", "hive-monitor-specialized")
```

### Example 2: Monitor with Hive-Mind Database

```bash
Task("Hive Monitor", "
Monitor hive-mind execution with database queries.

CONTEXT:
- Hive database: .hive-mind/hive.db
- Linear Issue: LOOP-456
- Archon Project: api-backend

MONITORING TASKS:
1. Query hive database for active agents:
   sqlite3 .hive-mind/hive.db 'SELECT * FROM agents WHERE status=\"active\"'
2. Check task assignments:
   sqlite3 .hive-mind/hive.db 'SELECT * FROM tasks ORDER BY priority DESC'
3. Monitor collective memory:
   sqlite3 .hive-mind/hive.db 'SELECT * FROM collective_memory WHERE created_at > datetime(\"now\", \"-5 minutes\")'
4. Verify agent coordination:
   sqlite3 .hive-mind/hive.db 'SELECT * FROM agent_communications ORDER BY timestamp DESC LIMIT 20'
5. Report findings to Linear with context
6. Update Archon task status based on hive progress

MONITOR TYPE: hive-mind (database-based)
", "hive-monitor-specialized")
```

## Key Differences from Generic Monitor

### âŒ Generic Monitor (Old Approach)
- Blind file counting
- No context understanding
- No Linear integration
- No architecture validation
- No requirement verification
- No collective memory communication
- Just bash commands

### âœ… Specialized Monitor (This Agent)
- **Context-aware**: Fetches Linear issue and Archon project
- **Intelligent analysis**: Understands file purpose and architecture
- **Requirement verification**: Checks against acceptance criteria
- **Pattern validation**: Verifies expected components exist
- **Team communication**: Updates Linear and Archon
- **Collective memory**: Queries and updates hive database
- **Recommendations**: Suggests improvements based on best practices

## Technical Implementation

### Recommended File Structure

```
PROJECT_DIR/
â”œâ”€â”€ src/                           # Monitor file creation here
â”œâ”€â”€ swarm-runs/                    # Monitor swarm logs
â”‚   â””â”€â”€ swarm_*/swarm.log
â”œâ”€â”€ .hive-mind/                    # Query hive database (if exists)
â”‚   â””â”€â”€ hive.db
â””â”€â”€ .monitor/                      # Store monitoring state
    â”œâ”€â”€ context.json               # Linear + Archon context
    â”œâ”€â”€ last_check_timestamp       # For incremental monitoring
    â””â”€â”€ progress_reports/          # Timestamped reports
```

### State Management

```bash
# Initialize monitoring state
mkdir -p $PROJECT_DIR/.monitor/progress_reports

# Store Linear context
echo "$LINEAR_ISSUE_JSON" > $PROJECT_DIR/.monitor/context.json

# Store Archon requirements
echo "$ARCHON_REQUIREMENTS_JSON" >> $PROJECT_DIR/.monitor/context.json

# Track last check time
date +%s > $PROJECT_DIR/.monitor/last_check_timestamp

# Generate timestamped reports
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
echo "$REPORT" > $PROJECT_DIR/.monitor/progress_reports/report_$TIMESTAMP.md
```

## Integration with Claude-Flow

### Agent Registry Entry

Add to `src/core/AgentRegistry.ts`:

```typescript
{
  type: "hive-monitor-specialized",
  name: "Hive Monitor (Specialized)",
  capabilities: [
    "linear-integration",
    "archon-integration",
    "context-awareness",
    "architecture-validation",
    "requirement-verification",
    "collective-memory",
    "intelligent-analysis"
  ],
  tools: [
    // Linear
    "mcp__linear-server__get_issue",
    "mcp__linear-server__create_comment",

    // Archon
    "mcp__archon__find_projects",
    "mcp__archon__find_tasks",
    "mcp__archon__get_project_features",

    // Claude Flow
    "mcp__claude-flow__swarm_status",
    "mcp__claude-flow__agent_metrics",

    // File operations
    "Read", "Glob", "Grep", "Bash"
  ],
  priority: "high",
  description: "Intelligent swarm monitoring with full Linear, Archon, and collective memory integration"
}
```

### Spawn Command

```bash
# Via Claude Code Task tool
Task("Hive Monitor", "[detailed monitoring instructions with Linear issue ID and Archon project ID]", "hive-monitor-specialized")

# Via claude-flow CLI (future implementation)
claude-flow agent spawn hive-monitor-specialized \
  --linear-issue LOOP-123 \
  --archon-project dgx-compute-mcp \
  --monitor-path /path/to/project \
  --frequency 60s
```

## Success Metrics

- âœ… Linear issue updated with progress every 2 minutes
- âœ… All requirements verified against implementation
- âœ… Architecture patterns validated
- âœ… Collective memory queried and updated (hive-mind)
- âœ… Final report includes recommendations
- âœ… Archon documents created with findings
- âœ… Context7 best practices referenced

## Future Enhancements

1. **Auto-intervention**: Automatically spawn helper agents if progress stalls
2. **Predictive analysis**: Use neural patterns to predict completion time
3. **Cost tracking**: Monitor token usage and estimate costs
4. **Performance benchmarking**: Compare against historical swarm executions
5. **Auto-testing**: Trigger test runs as components are completed
6. **Documentation generation**: Auto-generate docs from code analysis

---

**Agent Type**: `hive-monitor-specialized`
**Status**: Production-ready
**Version**: 1.0.0
**Last Updated**: 2025-11-04
